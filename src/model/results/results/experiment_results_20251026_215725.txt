============================================================
Transformer Experiment Results (EN→DE Translation)
============================================================
task: IWSLT2017 EN→DE Translation
seed: 42

config:
  model: {'d_model': 128, 'n_layers': 2, 'n_heads': 4, 'd_ff': 512, 'max_seq_len': 64, 'dropout': 0.1}
  training: {'batch_size': 32, 'lr': '3e-4', 'weight_decay': '1e-4', 'num_epochs': 1, 'lr_step_size': 5, 'lr_gamma': 0.1}
num_epochs: 1
final_train_loss: 4.501721124057112
final_val_loss: 3.4760114304883003
best_val_loss: 3.4760114304883003
device: cpu
timestamp: 20251026_215725
============================================================
